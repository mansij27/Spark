{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f8588b-42b9-4062-bd5f-befdf7a2ba0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_data= spark.read.format('csv').option('inferschema', True).option('Header', True).option('sep', '|').load('/FileStore/tables/User_Data.csv')\n",
    "user_data.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a39efdfc-c655-4489-a0d2-9ae5e54df967",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "# first 25 columns\n",
    "user_data.limit(25).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "871f6f6a-0003-4bf2-925e-fb40d59ba27b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# last 10 rows\n",
    "last_10_rows_df = user_data.tail(10)\n",
    "last_10_rows_df = spark.createDataFrame(last_10_rows_df).display()\n",
    "\n",
    "# better performance\n",
    "last_10_rows_df = user_data.orderBy(user_data.columns[0], ascending=False).limit(10).display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763647f1-a192-4acf-8fca-093725ab487a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Printing all columns name\n",
    "print(user_data.columns)\n",
    "\n",
    "user_data.select('Occupation').distinct().display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "647bb745-cbda-4de9-b074-e95d4ea2e86c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# most frequent occupation\n",
    "most_frequent_occupation = user_data.groupBy('Occupation').count().orderBy(col('count'), ascending=False).limit(1).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f637d11-d0ec-4f81-95bf-3cfa5bf542d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mean age of users\n",
    "mean_age = user_data.agg(mean('age')).display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0edb67d1-8786-4722-b594-f9404594c1b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# age with least occurrence\n",
    "least_age= user_data.groupBy('age').count().orderBy(col('count'), ascending=True).limit(5).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f94d338-d963-404b-8762-fc4a42bfe960",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating df from raw data with defined schema\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'],\n",
    "            'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'],\n",
    "            'deaths': [523, 52, 25, 616, 43, 234, 523, 62, 62, 73, 37, 35],\n",
    "            'battles': [5, 42, 2, 2, 4, 7, 8, 3, 4, 7, 8, 9],\n",
    "            'size': [1045, 957, 1099, 1400, 1592, 1006, 987, 849, 973, 1005, 1099, 1523],\n",
    "            'veterans': [1, 5, 62, 26, 73, 37, 949, 48, 48, 435, 63, 345],\n",
    "            'readiness': [1, 2, 3, 3, 2, 1, 2, 3, 2, 1, 2, 3],\n",
    "            'armored': [1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1],\n",
    "            'deserters': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n",
    "            'origin': ['Arizona', 'California', 'Texas', 'Florida', 'Maine', 'Iowa', 'Alaska', 'Washington', 'Oregon', 'Wyoming', 'Louisana', 'Georgia']}\n",
    "\n",
    "# Define the schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"regiment\", StringType(), True),\n",
    "    StructField(\"company\", StringType(), True),\n",
    "    StructField(\"deaths\", IntegerType(), True),\n",
    "    StructField(\"battles\", IntegerType(), True),\n",
    "    StructField(\"size\", IntegerType(), True),\n",
    "    StructField(\"veterans\", IntegerType(), True),\n",
    "    StructField(\"readiness\", IntegerType(), True),\n",
    "    StructField(\"armored\", IntegerType(), True),\n",
    "    StructField(\"deserters\", IntegerType(), True),\n",
    "    StructField(\"origin\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Create DataFrame using the raw data and the defined schema\n",
    "df = spark.createDataFrame(\n",
    "    [(tuple(x)) for x in zip(*raw_data.values())],\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "df.display()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "122224f7-7ff2-4398-9540-4014f29d156b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating df from raw data without schema\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "raw_data = {'regiment': ['Nighthawks', 'Nighthawks', 'Nighthawks', 'Nighthawks', 'Dragoons', 'Dragoons', 'Dragoons', 'Dragoons', 'Scouts', 'Scouts', 'Scouts', 'Scouts'],\n",
    "            'company': ['1st', '1st', '2nd', '2nd', '1st', '1st', '2nd', '2nd','1st', '1st', '2nd', '2nd'],\n",
    "            'deaths': [523, 52, 25, 616, 43, 234, 523, 62, 62, 73, 37, 35],\n",
    "            'battles': [5, 42, 2, 2, 4, 7, 8, 3, 4, 7, 8, 9],\n",
    "            'size': [1045, 957, 1099, 1400, 1592, 1006, 987, 849, 973, 1005, 1099, 1523],\n",
    "            'veterans': [1, 5, 62, 26, 73, 37, 949, 48, 48, 435, 63, 345],\n",
    "            'readiness': [1, 2, 3, 3, 2, 1, 2, 3, 2, 1, 2, 3],\n",
    "            'armored': [1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1],\n",
    "            'deserters': [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3],\n",
    "            'origin': ['Arizona', 'California', 'Texas', 'Florida', 'Maine', 'Iowa', 'Alaska', 'Washington', 'Oregon', 'Wyoming', 'Louisana', 'Georgia']}\n",
    "\n",
    "# Create DataFrame using the raw data and the defined schema\n",
    "df2 = spark.createDataFrame([tuple(x) for x in zip(*raw_data.values())], schema=list(raw_data.keys()))\n",
    "\n",
    "df2.display()\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1348c18e-3209-4afb-be0a-3ff50afc86ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  Select the 'deaths', 'size' and 'deserters' columns from Maine and Alaska\n",
    "filtter = df.filter(col('origin').isin(['Maine', 'Alaska'])).select('deaths', 'size', 'deserters', 'origin').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12f1f60f-1a9f-4287-b1de-7d4b94a0d131",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns = df.columns[2:6]  # Columns 3 to 6 (indexing starts at 0)\n",
    "columns2 = df.columns[5:8]  # Columns 5 to 8 \n",
    "\n",
    "df_selected_columns = df.select(*columns).display()\n",
    "df_selected_columns = df.select(*columns2).display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c9e1e68-8958-4d78-8128-b8fffbd920a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  rows where deaths is greater than 500 or less than 50\n",
    "df.filter((col(\"deaths\") > 500) | (col(\"deaths\") < 50)).display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b90f86eb-395a-440c-893c-52f98684ed88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# all the regiments not named \"Dragoons\"\n",
    "df.filter(col('regiment') != 'Dragoons').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55acdd9b-62ae-44dd-bfad-c91aca4a5c20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select the third cell down in the column named deaths\n",
    "row = df.select(\"deaths\").collect()[2][\"deaths\"]\n",
    "print(row)\n",
    "\n",
    "# cant use display have to create df that is why using print\n",
    "third_row_df = spark.createDataFrame([Row(deaths=row)]).display()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook 5 practice",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
